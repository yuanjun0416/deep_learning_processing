问题一：如何理解transform.Normlize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
答：前面的(0.5, 0.5, 0.5)是RGB三个通道上的均值，后面的(0.5, 0.5, 0.5)是RGB三个通道的标准差
    Normlize对每个通道执行一下操作：image_output = (image_input-mean)/std，参数mean和std分别以0.5和0.5的形式传递，这将使图像在[-1, 1]范围内归一化。
    例如：最小值0：image_output = (0-0.5)/0.5 = -1 ...
    '
    注意:
    通道顺序是RGB，用过openCV的同学应该知道openCV读出来的图像是BGR顺序。
    这两个tuple数据是用来对RGB图像做归一化的，比如名称Normlize所示这里都取0.5只是一个近似操作，实际上均值和方差并不是这么多，但是就这个示例而言，影响可不计

    精确值是通过分别计算R、G、B三个通道的数据算出来的，
    比如由两张图片，都是100*100大小的，R：那么两图片的像素点共有2*100*100=20000个，那么这两张图片的
    1. mean求法：
    mean_R: 这20000个像素点的R值加起来，除以像素点的总数，这里是20000；mean_G 和mean_B 两个通道的计算方法一样的。
    2. std求法：
    首先标准差就是开了方的方差，所以其实就是求方差，方差公式就是我们数学上的那个求方差的公式：
    也是3个通道分开算比如算R通道的， 这里X就为20000个像素点各自的R值，再减去R均值，上面已经算好了；
    然后平方；然后20000个像素点相加，然后求平均除以20000，得到R的方差，再开方得标准差。

    注意！！！
    如果你用的是自己创建的数据集，从头训练，那最好还是要自己统计自己数据集的这两个量

    你加载的的是pytorch上的预训练模型，自己只是微调模型；
    或者你用了常见的数据集比如VOC或者COCO之类的，但是用的是自己的网络结构，即pytorch上没有可选的预训练模型那么可以使用一个pytorch上给的通用的统计值：
    mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),即
    transform.Normlize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
    '

问题二：如何理解 predict_y = torch.max(outputs, dim=1)[1]中的含义
答：我们将此代码拆分一下 preidct = torch.max(outputs, dim=1) + predict_y = preidct[1]
    我们先简单看下列的代码
    import torch
    x = torch.rand([2, 4])
    y = torch.max(x, dim=1)[1]

    output:
    tensor([[0.4051, 0.1194, 0.7286, 0.8642, 0.5800, 0.0584, 0.2084, 0.4634, 0.3979,
         0.6835],
        [0.1506, 0.6964, 0.6613, 0.9141, 0.9811, 0.8798, 0.3690, 0.7334, 0.3589,
         0.5195]])
    tensor([3, 4]) 
    很明显x的最大值的索引下标分别是第一行的3，即0.8642，第二行的是4，即0.9811

    import torch
    x = torch.rand([2, 4])
    y = torch.max(x, dim=1)

    output:(由于x是随机赋值的，所以最大值的地方不一样)
    tensor([[0.2006, 0.0117, 0.6692, 0.8162, 0.5893, 0.5370, 0.1080, 0.8149, 0.1185,
         0.2816],
        [0.8734, 0.2172, 0.9733, 0.4813, 0.1112, 0.7972, 0.3073, 0.3147, 0.3988,
         0.3342]])
    torch.return_types.max(
    values=tensor([0.8162, 0.9733]),
    indices=tensor([3, 2]))
    很明显 y[1] = tensor([3, 2])
